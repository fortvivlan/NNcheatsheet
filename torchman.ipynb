{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5c612d-3477-4acc-adfd-5d1f209214f2",
   "metadata": {},
   "source": [
    "**Импорты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867f2632-79aa-4405-95c7-4790608311b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torch.utils.data import Subset\n",
    "from torchmetrics import Accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362dbe23-b6ee-49e0-9ac4-b9eca9780cfa",
   "metadata": {},
   "source": [
    "### Создание даталоадера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f4eb4-37aa-4a42-9e07-9e3b5b92a8df",
   "metadata": {},
   "source": [
    "#### Загрузка стандартного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83799df6-9b0f-43a2-9943-c98b47843d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это нужно обычно для работы с картинками\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ") \n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d116cd-6734-4954-8a36-2f4a903cc81c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Загрузка датасета из таблички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e906eb-f516-4731-8c15-b8453bd01766",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state = 42)\n",
    "# variant\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, :].values, y,\n",
    "                                                    test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbd804-dab4-438c-b031-3062a3cc37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(X_train, y_train, X_test, y_test):\n",
    "    train_tensor = torch.utils.data.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_tensor,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    test_tensor = torch.utils.data.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test))\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_tensor,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a771c2c-7d6d-43aa-affb-74d39578d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loader(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b928b1-cc2f-4fa0-be8e-0691dbfe6eb7",
   "metadata": {},
   "source": [
    "#### Загрузка картинок из папок с лейблами (директории вида data/class 1/..., data/class 2/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275a023-0ed5-4b9a-b33b-01c58e90e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        ToTensor(),\n",
    "        Normalize((0.3851, 0.3576, 0.3296), (0.2769, 0.2711, 0.2644))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder('data', transform=transform)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce4186-066c-4710-b089-7013414414d1",
   "metadata": {},
   "source": [
    "#### Создание своего класса для датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae9887-cb6d-46c4-9330-54f7bcadf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, word2id, DEVICE):\n",
    "        self.dataset = dataset['text'].values\n",
    "        self.word2id = word2id\n",
    "        self.length = dataset.shape[0]\n",
    "        self.target = dataset['tone'].values\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def __len__(self): #это обязательный метод, он должен уметь считать длину датасета\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index): #еще один обязательный метод. По индексу возвращает элемент выборки\n",
    "        tokens = self.preprocess(self.dataset[index]) # токенизируем\n",
    "        ids = torch.LongTensor([self.word2id[token] for token in tokens if token in self.word2id])\n",
    "        y = [self.target[index]]\n",
    "        return ids, y\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [token.strip(punctuation) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        return tokens\n",
    "\n",
    "    def collate_fn(self, batch): #этот метод можно реализовывать и отдельно,\n",
    "    # он понадобится для DataLoader во время итерации по батчам\n",
    "      ids, y = list(zip(*batch))\n",
    "      padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
    "      #мы хотим применять BCELoss, он будет брать на вход predicted размера batch_size x 1 (так как для каждого семпла модель будет отдавать одно число), target размера batch_size x 1\n",
    "      y = torch.Tensor(y).to(self.device) # tuple ([1], [0], [1])  -> Tensor [[1.], [0.], [1.]] \n",
    "      return padded_ids, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e3188-5667-4f9d-85a4-d8102d0e3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(train_sentences, word2id, DEVICE)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b720ee-158f-44c5-8204-99f0e9100ed7",
   "metadata": {},
   "source": [
    "#### Нормализация для картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4922b489-93bf-4886-a313-76f4c74647e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    \"\"\"Функция посчитает среднее и стандартное отклонение\"\"\"\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100c926-e0c1-4e58-a49c-312c52dfd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''загрузка датасета для подсчета нормализации'''\n",
    "transform = Compose(\n",
    "    [ToTensor()]\n",
    ")\n",
    "dataset = torch.utils.data.DataLoader(datasets.ImageFolder('data', transform=transform), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408ca7a-4fda-491c-b9f6-761c8b7a963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = get_mean_and_std(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cdc96-9421-4f72-bbd3-5263c1267636",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        ToTensor(),\n",
    "        Normalize(mean, std)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder('Cats', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee96b3-719e-4ab3-9dfa-397977f01ea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Циклы обучения, ванильный торч"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3b1d1-efa7-461b-bb90-fc40c5e8e5c9",
   "metadata": {},
   "source": [
    "#### Вариант 0 (essentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949de58-7f18-4d7d-92f5-9adcb917ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x_train, y_train in tqdm(train_dataloader):\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    if (which epoch we want):\n",
    "        val_loss = []\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad():  # альтернатива - model.eval(), не забыть потом перевести в model.train()\n",
    "            for x_val, y_val in tqdm(val_dataloader):\n",
    "                y_pred = model(x_val)\n",
    "                loss = loss_function(y_pred, y_val)\n",
    "                val_loss.append(loss.numpy())\n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "        print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dcaed-654b-47e3-b459-14d1f6269881",
   "metadata": {},
   "source": [
    "#### Вариант 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00397c64-1844-434e-990d-33aea1c20ff8",
   "metadata": {},
   "source": [
    "Модуль wandb &ndash; для отрисовки лоссов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c98fd3-1af8-416d-890b-57173f39841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb --upgrade --quiet\n",
    "import wandb\n",
    "\n",
    "# логинимся в своего пользователя (предварительно нужно ввести ключ из настроек с wandb.ai через консоль)\n",
    "wandb.login()\n",
    "# инициализируем проект\n",
    "wandb.init(project=\"pytorch-demo\")\n",
    "# сохраняем параметры сетки в wandb + просим следить за градиентами сетки\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7ca25-c27b-4156-b1d9-a9afa1d528ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всего у нас будет 5 эпох (5 раз подряд пройдемся по всем батчам из трейна)\n",
    "for epoch in range(5):\n",
    "    for x_train, y_train in tqdm(train_dataloader):    # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train)                        # делаем предсказания\n",
    "        loss = F.cross_entropy(y_pred, y_train)        # считаем лосс\n",
    "        loss.backward()                                # считаем градиенты обратным проходом\n",
    "        optimizer.step()                               # обновляем параметры сети\n",
    "        optimizer.zero_grad()                          # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        val_loss = []                                  # сюда будем складывать **средний по бачу** лосс\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad():                          # на валидации запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader):  # берем батч из вал лоадера\n",
    "                y_pred = model(x_val)                  # делаем предсказания\n",
    "                loss = F.cross_entropy(y_pred, y_val)  # считаем лосс\n",
    "                val_loss.append(loss.numpy())          # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "          \n",
    "        # скидываем метрики на wandb и автоматом смотрим на графики\n",
    "        wandb.log({\"mean val loss\": np.mean(val_loss),\n",
    "                   \"mean val accuracy\": np.mean(val_accuracy)})\n",
    "        \n",
    "        # печатаем метрики\n",
    "        print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cd3c8-161b-4e6b-aacb-fa2b68c2a301",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad63e3a-4aeb-4b18-8e5b-313b125ed412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, n_epochs=5):\n",
    "    for epoch in range(n_epochs):\n",
    "        # тренировка\n",
    "        for x_train, y_train in tqdm(train_dataloader):\n",
    "            y_pred = model(x_train)\n",
    "            loss = F.cross_entropy(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # валидация\n",
    "        if epoch % 2 == 0:\n",
    "            val_loss = []\n",
    "            val_accuracy = []\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in tqdm(val_dataloader):\n",
    "                    y_pred = model(x_val)\n",
    "                    loss = F.cross_entropy(y_pred, y_val)\n",
    "                    val_loss.append(loss.numpy())\n",
    "                    val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "\n",
    "            # печатаем метрики\n",
    "            print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d9197-a370-4192-897a-e50e1f7a4b97",
   "metadata": {},
   "source": [
    "#### Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6b89d-6607-4e7f-9e15-631174bf4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "train_loss_values = []\n",
    "train_accuracy_values = []\n",
    "valid_loss_values = []\n",
    "valid_accuracy = []\n",
    "\n",
    "def run_train():\n",
    "    step = 0\n",
    "    for epoch in range(80):\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = torchic(features)\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label.unsqueeze(1).float())\n",
    "            loss.backward()\n",
    "            acc = accuracy(output.squeeze(), label).item()\n",
    "\n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        train_loss_values.append(np.mean(running_loss))\n",
    "        train_accuracy_values.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print('EPOCH %d : train_loss: %f' % (epoch, train_loss_values[-1]))#, train_accuracy_values[-1]))\n",
    "\n",
    "\n",
    "        # Run validation\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in test_loader:\n",
    "            output = torchic(features)\n",
    "            loss = criterion(output, label.unsqueeze(1).float())\n",
    "            acc = accuracy(output.squeeze(), label).item()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "        valid_loss_values.append(np.mean(running_loss))\n",
    "        valid_accuracy.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print('EPOCH %d : valid_loss: %f' % (epoch, valid_loss_values[-1]), (valid_accuracy[-1]))\n",
    "        \n",
    "    return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e17d1f-41fa-434e-81a8-e82b646487d6",
   "metadata": {},
   "source": [
    "#### Вариант 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda33647-5f3d-481b-95ff-401e740e65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, optimizer, criterion, scheduler=None):\n",
    "    train_loss_values = []\n",
    "    train_accuracy_values = []\n",
    "    valid_loss_values = []\n",
    "    valid_accuracy = []\n",
    "    lr_history = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # run model on the chosen batch\n",
    "            output = model(features)\n",
    "\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "\n",
    "            # manual accuracy calculation; no torch lightning\n",
    "            acc = (output.argmax(dim=1)==label).sum() / len(label)\n",
    "\n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "\n",
    "        train_loss_values.append(np.mean(running_loss))\n",
    "        train_accuracy_values.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print('EPOCH %d,  train_loss: %f, valid_accuracy: %f' % (epoch, train_loss_values[-1], train_accuracy_values[-1]))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        # Run validation\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        with torch.no_grad(): # in validation loop we do not need gradients calculation; so switch it off\n",
    "            for features, label in test_loader:\n",
    "                output = model(features)\n",
    "                \n",
    "                # Calculate error ana accuracy\n",
    "                loss = criterion(output, label)\n",
    "                acc = (output.argmax(dim=1)==label).sum() / len(label)\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "                running_acc.append(acc)\n",
    "\n",
    "            valid_loss_values.append(np.mean(running_loss))\n",
    "            valid_accuracy.append(np.mean(running_acc))\n",
    "            if epoch % 20 == 0:\n",
    "                print('EPOCH %d, valid_loss: %f, valid_accuracy: %f' % (epoch, valid_loss_values[-1], valid_accuracy[-1]))\n",
    "\n",
    "        if scheduler is not None:\n",
    "            # Decay Learning Rate\n",
    "            scheduler.step()\n",
    "            lr_history.append(scheduler.get_last_lr())\n",
    "\n",
    "    if scheduler is not None:\n",
    "        return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy, lr_history\n",
    "        \n",
    "    return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c151c-43b9-4848-ba16-c1c8c4c5a6c5",
   "metadata": {},
   "source": [
    "### Архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655b504-3055-49c9-be79-a54a50fb51fd",
   "metadata": {},
   "source": [
    "#### Полносвязная сеть\n",
    "Создание стандартной модели\n",
    "\n",
    "(Документация по [nn.init](https://pytorch.org/docs/stable/nn.init.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7890ac2-5ae1-45b6-ae3a-9c78603cdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # variant: (in_features=input_size, out_features=hidden_size)\n",
    "        #optional inicialisation\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)  \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # так обычно не делают, я запилила для примера\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Далее можно писать с разной степенью развернутости, у меня здесь непоследовательно'''\n",
    "        x = self.fc1(x)  # первый слой\n",
    "        x = self.activation(self.batchnorm(x))  # нормализация после первого слоя и перед активацией\n",
    "        x = self.fc2(x)  # второй слой \n",
    "        x = self.activation(self.dropout(x))  # дропаут тоже перед активацией\n",
    "        x = self.fc3(x)  # выходной слой\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360eb03-2235-4f60-a28c-3ba7d2275370",
   "metadata": {},
   "source": [
    "Более простой вариант с Sequential (mauvais ton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a32e90-c3e6-482c-a87a-09ffc8696d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetEncoder(nn.Module):\n",
    "    def __init__(self, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.batch_norm = torch.nn.BatchNorm2d(1)\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.linear1 = torch.nn.Linear(in_features=64 * 5 * 5, out_features=128)\n",
    "        self.linear2 = torch.nn.Linear(in_features=128, out_features=64)\n",
    "        self.output = torch.nn.Linear(in_features=64, out_features=10)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f89711-2aae-41d3-b0f8-9d540faa8e97",
   "metadata": {},
   "source": [
    "Совсем тупой вариант с Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df2f90-a5af-4555-aeaa-e79bde4bdc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = nn.Sequential(\n",
    "        \n",
    "        # Добавляем в нашу модель первый слой из 25 нейронов\n",
    "        nn.Linear(in_features=INPUT_SIZE, out_features=HIDDEN_SIZE),\n",
    "        nn.Sigmoid(),\n",
    "        \n",
    "        # Добавляем ещё один слой из 25 нейронов\n",
    "        nn.Linear(in_features=HIDDEN_SIZE, out_features=HIDDEN_SIZE),\n",
    "        nn.Sigmoid(),\n",
    "        \n",
    "        # Выходной вектор на количество классов, получаем с помощью такого же линейного приеобразования,\n",
    "        # как и предыдущие слои, но уже на нужное количество выходных нейронов (т.е. классов)\n",
    "        nn.Linear(in_features=HIDDEN_SIZE, out_features=OUTPUT_SIZE),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85731cc3-c9ad-4768-9182-89b924f1b58a",
   "metadata": {},
   "source": [
    "#### CNN, VGG слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcfc38-2ad4-4e85-8c91-e148b202d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Torchic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # VGG\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(124 * 124 * 20, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbdd724-5667-4827-b845-a85492b68cfd",
   "metadata": {},
   "source": [
    "Как вычислять размер первого полносвязного слоя после VGG:\n",
    "\n",
    "1. Размер картинки x \\* y \\* количество каналов -> (размер картинки - размер ядра + 1) \\*\\* 2 \\* количество сверток\n",
    "2. Если макспул - поделить на макспул\n",
    "\n",
    "Например, если картинка 32\\*32\\*3 и размер ядра 5, количество сверток после первого слоя 10:\n",
    "\n",
    "    32*32 => 32 - 4 = 28*28*10\n",
    "    макспул 2:\n",
    "    14*14*10\n",
    "    второй слой свертки на 10, 20 с ядром 3:\n",
    "    12*12*20\n",
    "    \n",
    "Как в сетке выше получилось 124\\*124\\*20:\n",
    "\n",
    "    размер картинок был 256*256*3\n",
    "    1. 256*256*3 - 4 = 252*252*10\n",
    "    2. -4: 248*248*20\n",
    "    3. maxpool 2: 124*124*20\n",
    "    \n",
    "Готово, вы прекрасны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9179aee-97be-433d-b141-b482e46beb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
